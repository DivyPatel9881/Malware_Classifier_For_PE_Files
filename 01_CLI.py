import operator
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import StandardScaler
import time

def getXY(path):
    # getting unimp features
    unimp_features = {
     'AddressOfEntryPoint': 0,
     'BaseOfCode': 0,
     'BaseOfData': 0,
     'Characteristics': 1032.206797186472,
     'CheckSum': 0,
     'DllCharacteristics': 1478.4954869782816,
     'ExportNb': 0,
     'FileAlignment': 0,
     # 'ImageBase': 530.5361006533311,
     'ImageBase': 0,
     'ImportsNb': 0,
     'ImportsNbDLL': 0,
     'ImportsNbOrdinal': 0,
     'LoadConfigurationSize': 0,
     'LoaderFlags': 0,
     'Machine': 1082.9256010888016,
     'MajorImageVersion': 0,
     'MajorLinkerVersion': 0,
     'MajorOperatingSystemVersion': 236.61647685302975,
     'MajorSubsystemVersion': 487.3898733331374,
     'MinorImageVersion': 0,
     'MinorLinkerVersion': 0,
     'MinorOperatingSystemVersion': 0,
     'MinorSubsystemVersion': 0,
     'Name': 0,
     'NumberOfRvaAndSizes': 0,
     'ResourcesMaxEntropy': 441.8248905853912,
     'ResourcesMaxSize': 0,
     'ResourcesMeanEntropy': 0,
     'ResourcesMeanSize': 0,
     'ResourcesMinEntropy': 353.224684768646,
     'ResourcesMinSize': 8.160597671881105,
     'ResourcesNb': 0,
     'SectionAlignment': 0,
     'SectionMaxRawsize': 0,
     'SectionMaxVirtualsize': 0,
     'SectionsMaxEntropy': 580.740479410044,
     'SectionsMeanEntropy': 72.19620856510386,
     'SectionsMeanRawsize': 0,
     'SectionsMeanVirtualsize': 0,
     'SectionsMinEntropy': 158.0840575679675,
     'SectionsMinRawsize': 0,
     'SectionsMinVirtualsize': 0,
     'SectionsNb': 7.795926354766131,
     'SizeOfCode': 0,
     'SizeOfHeaders': 0,
     'SizeOfHeapCommit': 0,
     'SizeOfHeapReserve': 0,
     'SizeOfImage': 0,
     'SizeOfInitializedData': 0,
     'SizeOfOptionalHeader': 393.1119115064255,
     'SizeOfStackCommit': 0,
     'SizeOfStackReserve': 93.14759692294628,
     'SizeOfUninitializedData': 0,
     'Subsystem': 590.0487097835594,
     'VersionInformationSize': 648.0362688739431,
     'md5': 0}
    unimp_features = sorted(unimp_features.items(), key=operator.itemgetter(1))
    unimp_features.reverse()
    unimp_features = unimp_features[16:]
    for i in range(len(unimp_features)):
        unimp_features[i] = unimp_features[i][0]
    
    # reading data
    dataset = pd.read_csv(path)
    dataset = dataset[dataset.columns.difference(unimp_features)]
    X = dataset.iloc[:,:-1].values
    y = dataset.iloc[:,-1].values
    
    # one-hot encoding (Categorical Data)
    from sklearn.preprocessing import LabelEncoder, OneHotEncoder
    labelencoder_X = LabelEncoder()
    
    # Label encoding
    X[:, 0] = labelencoder_X.fit_transform(X[:, 0])
    X[:, 1] = labelencoder_X.fit_transform(X[:, 1])
    X[:, 2] = labelencoder_X.fit_transform(X[:, 2])
    X[:, 3] = labelencoder_X.fit_transform(X[:, 3])
    X[:, 4] = labelencoder_X.fit_transform(X[:, 4])
    X[:, 14] = labelencoder_X.fit_transform(X[:, 14])
    
    for i in range(len(X[:, 14])):
        X[i, 14], X[i, 5] = X[i, 5], X[i, 14]
    
    onehotencoder = OneHotEncoder()
    Z = onehotencoder.fit_transform(X[:, :1]).toarray()
    Z = Z[:, 1:]
    X = X[:, 1:]
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    X = np.concatenate((Z, X), 1)
    
    # Scaling
    sc_X = StandardScaler()
    X = sc_X.fit_transform(X)
    
    return X, y

X, y = getXY('/home/yash/Documents/Malware_Classifier_For_PE_Files/cleaned_data.csv')

# train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

### ----------------- LR -------------------- ###

from Models.Logistic import Logistic

start_time = time.time()
modelLR = Logistic(X_train, y_train)
print("Time Taken to Train: {}".format(time.time() - start_time))

y_pred = modelLR.predict(X_test)

count = 0
for i in range(len(y_pred)):
    if y_pred[i] == y_test[i]:
        count += 1

acc = (count / len(y_pred)) * 100
print('Logistic Reg Accuracy: {}\n'.format(acc))

### ---------------- Random Forest ---------------------- ###

from Models.RandomForest import RandomForest

start_time = time.time()
modelRF = RandomForest(X_train, y_train, 400)
print("Time Taken to Train: {}".format(time.time() - start_time))

y_pred = modelRF.predict(X_test)

count = 0
for i in range(len(y_pred)):
    if y_pred[i] == y_test[i]:
        count += 1

acc = (count / len(y_pred)) * 100
print('Random Forest Accuracy: {}\n'.format(acc))

### ------------------------ SVM --------------------------- ###

from Models.SVM import SVM

start_time = time.time()
modelSVM = SVM(X_train, y_train, 'rbf')
print("Time Taken to Train: {}".format(time.time() - start_time))

y_pred = modelSVM.predict(X_test)

count = 0
for i in range(len(y_pred)):
    if y_pred[i] == y_test[i]:
        count += 1

acc = (count / len(y_pred)) * 100
print('SVM with rbf Accuracy: {}\n'.format(acc))

### ---------------------- AdaBoost ------------------------- ###

from Models.AdaBoost import AdaBoost

start_time = time.time()
modelAda = AdaBoost(X_train, y_train, 100, 0.01)
print("Time Taken to Train: {}".format(time.time() - start_time))

y_pred = modelAda.predict(X_test)

count = 0
for i in range(len(y_pred)):
    if y_pred[i] == y_test[i]:
        count += 1

acc = (count / len(y_pred)) * 100
print('AdaBoost Accuracy: {}\n'.format(acc))

## ----------------------- KNN ------------------------------ ###

from Models.KNeighbors import KNeighbors

start_time = time.time()
modelKNN = KNeighbors(X_train, y_train, 10)
print("Time Taken to Train: {}".format(time.time() - start_time))

y_pred = modelKNN.predict(X_test)

count = 0
for i in range(len(y_pred)):
    if y_pred[i] == y_test[i]:
        count += 1

acc = (count / len(y_pred)) * 100
print('KNeighbors Accuracy: {}\n'.format(acc))

### --------------------- Gradient Boosting ---------------- ###

from Models.GradientBoosting import GradientBoosting

start_time = time.time()
modelGB = GradientBoosting(X_train, y_train, 100, 0.01)
print("Time Taken to Train: {}".format(time.time() - start_time))

y_pred = modelGB.predict(X_test)

count = 0
for i in range(len(y_pred)):
    if y_pred[i] == y_test[i]:
        count += 1

acc = (count / len(y_pred)) * 100
print('Gradient Boosting Accuracy: {}\n'.format(acc))

### -------------------- XGBoost --------------------------- ###

from Models.XGBoost import XGBoost

start_time = time.time()
modelXGB = XGBoost(X_train, y_train, 100, 0.01)
print("Time Taken to Train: {}".format(time.time() - start_time))

y_pred = modelXGB.predict(X_test)

count = 0
for i in range(len(y_pred)):
    if y_pred[i] == y_test[i]:
        count += 1

acc = (count / len(y_pred)) * 100
print('XGBoost Accuracy: {}\n'.format(acc))

### --------------------- Decision Tree ------------------------ ###

from Models.DecisionTree import Fit

start_time = time.time()
modelDT = Fit(X_train, y_train)
print("Time Taken to Train: {}".format(time.time() - start_time))

y_pred = modelDT.predict(X_test)

count = 0
for i in range(len(y_pred)):
    if y_pred[i] == y_test[i]:
        count += 1

acc = (count / len(y_pred)) * 100
print('Decision Tree Accuracy: {}\n'.format(acc))

### -------------------------------------------------------- ###

while (True):
    print("Enter the file name: ")
    s = input()
    x, y = getXY(s)

    print("Logistic Regression")
    score = modelLR.predict_proba(x)
    print("Malicious: {}".format(score))
    if score <= 0.3:
        print("Verdict: {}".format("Low"))
    elif score <= 0.6:
        print("Verdict: {}".format("Medium"))
    else:
        print("Verdict: {}".format("High"))
    print()

    print("Random Forest")
    score = modelRF.predict_proba(x)
    print("Malicious: {}".format(score))
    if score <= 0.3:
        print("Verdict: {}".format("Low"))
    elif score <= 0.6:
        print("Verdict: {}".format("Medium"))
    else:
        print("Verdict: {}".format("High"))
    print()

    print("SVM")
    score = modelSVM.predict_proba(x)
    print("Malicious: {}".format(score))
    if score <= 0.3:
        print("Verdict: {}".format("Low"))
    elif score <= 0.6:
        print("Verdict: {}".format("Medium"))
    else:
        print("Verdict: {}".format("High"))
    print()

    print("AdaBoost")
    score = modelAda.predict_proba(x)
    print("Malicious: {}".format(score))
    if score <= 0.3:
        print("Verdict: {}".format("Low"))
    elif score <= 0.6:
        print("Verdict: {}".format("Medium"))
    else:
        print("Verdict: {}".format("High"))
    print()

    print("K Nearest Neighbors")
    score = modelKNN.predict_proba(x)
    print("Malicious: {}".format(score))
    if score <= 0.3:
        print("Verdict: {}".format("Low"))
    elif score <= 0.6:
        print("Verdict: {}".format("Medium"))
    else:
        print("Verdict: {}".format("High"))
    print()

    print("Gradient Boosting")
    score = modelGB.predict_proba(x)
    print("Malicious: {}".format(score))
    if score <= 0.3:
        print("Verdict: {}".format("Low"))
    elif score <= 0.6:
        print("Verdict: {}".format("Medium"))
    else:
        print("Verdict: {}".format("High"))
    print()

    print("XGBoost")
    score = modelXGB.predict_proba(x)
    print("Malicious: {}".format(score))
    if score <= 0.3:
        print("Verdict: {}".format("Low"))
    elif score <= 0.6:
        print("Verdict: {}".format("Medium"))
    else:
        print("Verdict: {}".format("High"))
    print()

    print("Decision Tree")
    score = modelDT.predict_proba(x)
    print("Malicious: {}".format(score))
    if score <= 0.3:
        print("Verdict: {}".format("Low"))
    elif score <= 0.6:
        print("Verdict: {}".format("Medium"))
    else:
        print("Verdict: {}".format("High"))
    print()