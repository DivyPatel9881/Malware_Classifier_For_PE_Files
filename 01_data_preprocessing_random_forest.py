import operator
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import StandardScaler
import time

start_time = time.time()

def getXY(path):
    # getting unimp features
    unimp_features = {
     'AddressOfEntryPoint': 0,
     'BaseOfCode': 0,
     'BaseOfData': 0,
     'Characteristics': 1032.206797186472,
     'CheckSum': 0,
     'DllCharacteristics': 1478.4954869782816,
     'ExportNb': 0,
     'FileAlignment': 0,
     # 'ImageBase': 530.5361006533311,
     'ImageBase': 0,
     'ImportsNb': 0,
     'ImportsNbDLL': 0,
     'ImportsNbOrdinal': 0,
     'LoadConfigurationSize': 0,
     'LoaderFlags': 0,
     'Machine': 1082.9256010888016,
     'MajorImageVersion': 0,
     'MajorLinkerVersion': 0,
     'MajorOperatingSystemVersion': 236.61647685302975,
     'MajorSubsystemVersion': 487.3898733331374,
     'MinorImageVersion': 0,
     'MinorLinkerVersion': 0,
     'MinorOperatingSystemVersion': 0,
     'MinorSubsystemVersion': 0,
     'Name': 0,
     'NumberOfRvaAndSizes': 0,
     'ResourcesMaxEntropy': 441.8248905853912,
     'ResourcesMaxSize': 0,
     'ResourcesMeanEntropy': 0,
     'ResourcesMeanSize': 0,
     'ResourcesMinEntropy': 353.224684768646,
     'ResourcesMinSize': 8.160597671881105,
     'ResourcesNb': 0,
     'SectionAlignment': 0,
     'SectionMaxRawsize': 0,
     'SectionMaxVirtualsize': 0,
     'SectionsMaxEntropy': 580.740479410044,
     'SectionsMeanEntropy': 72.19620856510386,
     'SectionsMeanRawsize': 0,
     'SectionsMeanVirtualsize': 0,
     'SectionsMinEntropy': 158.0840575679675,
     'SectionsMinRawsize': 0,
     'SectionsMinVirtualsize': 0,
     'SectionsNb': 7.795926354766131,
     'SizeOfCode': 0,
     'SizeOfHeaders': 0,
     'SizeOfHeapCommit': 0,
     'SizeOfHeapReserve': 0,
     'SizeOfImage': 0,
     'SizeOfInitializedData': 0,
     'SizeOfOptionalHeader': 393.1119115064255,
     'SizeOfStackCommit': 0,
     'SizeOfStackReserve': 93.14759692294628,
     'SizeOfUninitializedData': 0,
     'Subsystem': 590.0487097835594,
     'VersionInformationSize': 648.0362688739431,
     'md5': 0}
    unimp_features = sorted(unimp_features.items(), key=operator.itemgetter(1))
    unimp_features.reverse()
    unimp_features = unimp_features[16:]
    for i in range(len(unimp_features)):
        unimp_features[i] = unimp_features[i][0]
    
    # reading data
    dataset = pd.read_csv(path)
    dataset = dataset[dataset.columns.difference(unimp_features)]
    X = dataset.iloc[:,:-1].values
    y = dataset.iloc[:,-1].values
    
    # one-hot encoding (Categorical Data)
    from sklearn.preprocessing import LabelEncoder, OneHotEncoder
    labelencoder_X = LabelEncoder()
    
    # Label encoding
    X[:, 0] = labelencoder_X.fit_transform(X[:, 0])
    X[:, 1] = labelencoder_X.fit_transform(X[:, 1])
    X[:, 2] = labelencoder_X.fit_transform(X[:, 2])
    X[:, 3] = labelencoder_X.fit_transform(X[:, 3])
    X[:, 4] = labelencoder_X.fit_transform(X[:, 4])
    X[:, 14] = labelencoder_X.fit_transform(X[:, 14])
    
    for i in range(len(X[:, 14])):
        X[i, 14], X[i, 5] = X[i, 5], X[i, 14]
    
    onehotencoder = OneHotEncoder()
    Z = onehotencoder.fit_transform(X[:, :1]).toarray()
    Z = Z[:, 1:]
    X = X[:, 1:]
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    W = onehotencoder.fit_transform(X[:, :1]).toarray()
    W = W[:, 1:]
    X = X[:, 1:]
    Z = np.concatenate((Z, W), 1)
    
    X = np.concatenate((Z, X), 1)
    
    # Scaling
    sc_X = StandardScaler()
    X = sc_X.fit_transform(X)
    
    return X, y

X, y = getXY('/home/yash/Documents/Malware_Classifier_For_PE_Files/cleaned_data.csv')

# train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

### ----------------- LR -------------------- ###
from Models.RandomForest import RandomForest
model = RandomForest(X_train, y_train, 400)

y_pred = model.predict(X_test)
print("Time Taken to Train: {}".format(time.time() - start_time))

count = 0
for i in range(len(y_pred)):
    if y_pred[i] == y_test[i]:
        count += 1

acc = (count / len(y_pred)) * 100
print('Random Forest: {}'.format(acc))

### ----------------------------------------- ###